[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jenny Shyu",
    "section": "",
    "text": "Hi there! I’m Jenny Shyu, I’m passionate about leveraging quantitative methods, data, and technology to generate meaningful insights and tackle real-world business problems.\n\n\n\n\n\n\nM.S. Business Analytics | UCSD 2024-Present\nB.S. Mathematics & Economics, Computational Social Science Minor | UCSD 2021-2024\n\n\n\n\n\n\nExperian | Capstone Project | March 2025 - Present\nUCSD Rady | Graduate Teaching Assistant | MGT 172 Business Project Management | October 2024 - Present\nLPL Financial | Technology Intern | June 2024 - August 2024\nLumnus Consulting | VP Data Analytics | November 2022 - June 2024"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Jenny Shyu",
    "section": "",
    "text": "Hi there! I’m Jenny Shyu, a Master’s student in Business Analytics at UC San Diego’s Rady School of Management with a background in Math-Econ.\n\n\nI’m passionate about leveraging quantitative methods, data, and technology to generate meaningful insights and tackle real-world business problems.\n\n\n\nMost recently, I interned at LPL Financial, where I worked with financial data and dashboards. I also served as the VP of Data Analytics in a student consulting organization and currently work as a Graduate Teaching Assistant for a Business Project Management course—helping students apply frameworks like prioritization matrices in real-world project planning.\nIn the past, I also trained and competed as a figure skater representing Chinese Taipei."
  },
  {
    "objectID": "index.html#current",
    "href": "index.html#current",
    "title": "Jenny Shyu",
    "section": "",
    "text": "Capstone Project | Experian\nGraduate Teaching Assistant, MGT 172 Business Project Management | UCSD Rady"
  },
  {
    "objectID": "index.html#work-history",
    "href": "index.html#work-history",
    "title": "Jenny Shyu",
    "section": "",
    "text": "GBK Collective | 2022 - Present\nBain & Co | 2020 - 2021\nCornerstone Research | 2006 - 2014"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Jenny Shyu",
    "section": "",
    "text": "M.S. Business Analytics | UCSD 2024-Present\nB.S. Mathematics & Economics, Computational Social Science Minor | UCSD 2021-2024"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Jenny Shyu",
    "section": "",
    "text": "Experian | Capstone Project | March 2025 - Present\nUCSD Rady | Graduate Teaching Assistant | MGT 172 Business Project Management | October 2024 - Present\nLPL Financial | Technology Intern | June 2024 - August 2024\nLumnus Consulting | VP Data Analytics | November 2022 - June 2024"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nJenny Shyu\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "hw1_questions.html",
    "href": "hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to replicate their results. The goal of the experiment was to test whether offering a matching donation—in which a lead donor promises to match contributions from other individuals—would increase the likelihood and/or size of charitable donations. In addition to testing whether matching grants were effective in general, Karlan and List also explored whether the size of the match mattered. Some participants were told that every dollar they donated would be matched 1:1, while others were offered more generous matches (2:1 or 3:1), allowing the researchers to test for differences in donor behavior across match sizes.\nThe experiment is notable for its scale, randomization, and use of real-world donor behavior, which together provide credible evidence of causal effects. Because the fundraising letters were identical in every respect except for the treatment condition, any differences in outcomes across groups can be attributed to the match offer itself. This approach allows for insights not only into how people respond to incentives, but also into broader questions about social influence, perceived impact, and behavioral nudges in charitable giving."
  },
  {
    "objectID": "hw1_questions.html#introduction",
    "href": "hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to replicate their results. The goal of the experiment was to test whether offering a matching donation—in which a lead donor promises to match contributions from other individuals—would increase the likelihood and/or size of charitable donations. In addition to testing whether matching grants were effective in general, Karlan and List also explored whether the size of the match mattered. Some participants were told that every dollar they donated would be matched 1:1, while others were offered more generous matches (2:1 or 3:1), allowing the researchers to test for differences in donor behavior across match sizes.\nThe experiment is notable for its scale, randomization, and use of real-world donor behavior, which together provide credible evidence of causal effects. Because the fundraising letters were identical in every respect except for the treatment condition, any differences in outcomes across groups can be attributed to the match offer itself. This approach allows for insights not only into how people respond to incentives, but also into broader questions about social influence, perceived impact, and behavioral nudges in charitable giving."
  },
  {
    "objectID": "hw1_questions.html#data",
    "href": "hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\nimport pandas as pd\n\ndata = pd.read_stata(\"karlan_list_2007.dta\")\ndata.head()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\n\ndata.describe()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio2\nratio3\nsize25\nsize50\nsize100\nsizeno\naskd1\naskd2\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n49978.000000\n49978.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nmean\n0.666813\n0.333187\n0.222311\n0.222211\n0.166723\n0.166623\n0.166723\n0.166743\n0.222311\n0.222291\n...\n0.510245\n0.488715\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\n0.415803\n0.415736\n0.372732\n0.372643\n0.372732\n0.372750\n0.415803\n0.415790\n...\n0.499900\n0.499878\n0.168560\n0.135868\n0.103039\n0.378105\n22027.316665\n0.193405\n0.186599\n0.258633\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n0.000000\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n1.000000\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n8 rows × 48 columns\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper).\nAs an ad hoc test of the randomization mechanism, I compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another at the 95% confidence level. If randomization was properly executed, we should expect no statistically significant differences in pre-treatment characteristics between the groups.\nI begin by testing the variable mrm2, which captures the number of months since the last donation. This variable is useful for checking balance because it is unrelated to the treatment assignment and reflects donor history.\n\nimport pandas as pd\nimport statsmodels.formula.api as smf\nfrom scipy import stats\n\n\ndata = pd.read_stata(\"karlan_list_2007.dta\")\n\nvars_to_test = [\"mrm2\", \"amount\", \"years\", \"freq\"]\nresults = []\n\nfor var in vars_to_test:\n    subset = data[[\"treatment\", var]].dropna()\n    control = subset[subset[\"treatment\"] == 0][var]\n    treatment = subset[subset[\"treatment\"] == 1][var]\n    \n    # T-test\n    t_stat, p_val = stats.ttest_ind(treatment, control, equal_var=False)\n    \n    # Linear regression\n    regression = smf.ols(f\"{var} ~ treatment\", data=subset).fit()\n    coef = regression.params[\"treatment\"]\n    reg_p = regression.pvalues[\"treatment\"]\n    \n    # Difference in means\n    diff = treatment.mean() - control.mean()\n    \n    results.append({\n        \"Variable\": var,\n        \"Diff (Treat - Control)\": round(diff, 5),\n        \"T-test p-value\": round(p_val, 5),\n        \"Regression Coef\": round(coef, 5),\n        \"Regression p-value\": round(reg_p, 5)\n    })\n\npd.DataFrame(results)\n\n\n\n\n\n\n\n\nVariable\nDiff (Treat - Control)\nT-test p-value\nRegression Coef\nRegression p-value\n\n\n\n\n0\nmrm2\n0.01369\n0.90485\n0.01369\n0.90489\n\n\n1\namount\n0.15361\n0.05509\n0.15361\n0.06282\n\n\n2\nyears\n-0.05755\n0.27532\n-0.05755\n0.27002\n\n\n3\nfreq\n-0.01198\n0.91174\n-0.01198\n0.91170\n\n\n\n\n\n\n\nThe table of results above shows no statistically significant differences at the 5% level for any variable (p-values &gt; 0.05), though amount is marginally close (p ≈ 0.06 in the regression). This is consistent with proper random assignment.\nThese checks are similar to what Karlan and List report in Table 1 of the original paper, which reassures readers that the treatment effect estimates later in the paper can be interpreted as causal. If pre-treatment covariates are balanced, then observed differences in outcomes are more likely attributable to the randomized treatment itself.\n\nInterpretation\nThese results mirror those presented in Table 1 of Karlan and List (2007), which shows no significant differences between the groups in prior donation behavior and demographic characteristics. Table 1 serves to reassure the reader that any observed treatment effects later in the analysis can be confidently attributed to the randomized intervention rather than pre-existing differences between groups."
  },
  {
    "objectID": "hw1_questions.html#experimental-results",
    "href": "hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\nDonation Rate by Group\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Calculate donation rates\ndonation_rates = data.groupby(\"treatment\")[\"gave\"].mean().reset_index()\ndonation_rates[\"group\"] = donation_rates[\"treatment\"].map({0: \"Control\", 1: \"Treatment\"})\n\n# Create barplot\nplt.figure(figsize=(6, 4))\nax = sns.barplot(data=donation_rates, x=\"group\", y=\"gave\")\nplt.ylabel(\"Proportion Donated\")\nplt.xlabel(\"\")\nplt.title(\"Donation Rate by Group\")\nplt.ylim(0, 0.03)\nplt.grid(axis='y')\n\n# Add percentage labels on top\nfor i, val in enumerate(donation_rates[\"gave\"]):\n    ax.text(i, val + 0.0005, f\"{val:.3%}\", ha='center', va='bottom')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis bar plot shows that the treatment group—who received matching grant letters—had a higher donation rate than the control group.\n\n\nT-Test and Linear Regression\n\ntreat_gave = data[data['treatment'] == 1]['gave']\ncontrol_gave = data[data['treatment'] == 0]['gave']\nt_stat, t_pval = stats.ttest_ind(treat_gave, control_gave, equal_var=False)\n\n# Format output\npd.DataFrame([{\n    \"T-test Statistic\": round(t_stat, 3),\n    \"T-test p-value\": round(t_pval, 5)\n}])\n\n\n\n\n\n\n\n\nT-test Statistic\nT-test p-value\n\n\n\n\n0\n3.209\n0.00133\n\n\n\n\n\n\n\n\ngave_regression = smf.ols(\"gave ~ treatment\", data=data).fit()\ncoef = gave_regression.params[\"treatment\"]\nstd_err = gave_regression.bse[\"treatment\"]\np_val = gave_regression.pvalues[\"treatment\"]\nconf_int = gave_regression.conf_int().loc[\"treatment\"]\n\n# Format output\npd.DataFrame([{\n    \"Treatment Coefficient\": round(coef, 5),\n    \"Standard Error\": round(std_err, 5),\n    \"p-value\": round(p_val, 5),\n    \"95% CI Lower\": round(conf_int[0], 5),\n    \"95% CI Upper\": round(conf_int[1], 5)\n}])\n\n\n\n\n\n\n\n\nTreatment Coefficient\nStandard Error\np-value\n95% CI Lower\n95% CI Upper\n\n\n\n\n0\n0.00418\n0.00135\n0.00193\n0.00154\n0.00682\n\n\n\n\n\n\n\nThe difference in donation rates is statistically significant at the 1% level.\nThe treatment group is more likely to donate, increasing the probability of giving by about 0.42 percentage points.\nThis replicates the result from Table 2A Panel A in Karlan & List (2007), showing that a match offer significantly boosts participation.\nOLS regression shows a statistically significant positive coefficient (≈ 0.0042) on the treatment variable. This confirms the t-test: assignment to the treatment group increased the likelihood of making a donation.\nThis suggests that even a small behavioral nudge like mentioning a matching donation makes people more likely to contribute to charity. People respond to the perception of increased impact.\n\n# Probit model\nimport statsmodels.api as sm\n\nprobit_model = smf.probit(\"gave ~ treatment\", data=data).fit()\ncoef = probit_model.params[\"treatment\"]\nstd_err = probit_model.bse[\"treatment\"]\np_val = probit_model.pvalues[\"treatment\"]\nconf_int = probit_model.conf_int().loc[\"treatment\"]\n\n# Output summary\npd.DataFrame([{\n    \"Probit Coefficient\": round(coef, 5),\n    \"Standard Error\": round(std_err, 5),\n    \"p-value\": round(p_val, 5),\n    \"95% CI Lower\": round(conf_int[0], 5),\n    \"95% CI Upper\": round(conf_int[1], 5)\n}])\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\n\n\n\n\n\n\n\n\nProbit Coefficient\nStandard Error\np-value\n95% CI Lower\n95% CI Upper\n\n\n\n\n0\n0.08678\n0.02788\n0.00185\n0.03214\n0.14143\n\n\n\n\n\n\n\nThe probit model replicates Table 3, Column 1 of Karlan and List (2007), with a significant positive treatment effect (coefficient ≈ 0.087, p ≈ 0.002). This again confirms that individuals are more likely to donate when offered a matching grant.\nTogether, these results demonstrate a consistent and statistically significant treatment effect, providing strong evidence that the framing of charitable solicitations matters for donor behavior.\nThe match incentive not only has a practical impact but also a statistically robust one, even under a probit framework.\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\nalso include p-velue 2:1 vs 1:1, 3:1 vs 2:1, 3:1 vs 1:1\nfor ols regresssion only have intercept, ration2, ratio3\nraw difference (2:1-1:1) raw difference (3:1 - 2:1) fitted difference (2:1 - 1:1) fitted difference (3:1 - 2:1)\n\nResponse Rates by Match Ratio\n\nmatched_data = data[(data[\"treatment\"] == 1) & (data[\"ratio\"].isin([1, 2, 3]))]\n\n# Calculate means\nresponse_rates = matched_data.groupby(\"ratio\")[\"gave\"].mean()\n\n# Separate groups for pairwise comparisons\ngave_1 = matched_data[matched_data[\"ratio\"] == 1][\"gave\"]\ngave_2 = matched_data[matched_data[\"ratio\"] == 2][\"gave\"]\ngave_3 = matched_data[matched_data[\"ratio\"] == 3][\"gave\"]\n\n# T-tests for pairwise comparisons\nfrom scipy import stats\n\nsummary = pd.DataFrame({\n    \"Comparison\": [\"2:1 vs 1:1\", \"3:1 vs 2:1\", \"3:1 vs 1:1\"],\n    \"p-value\": [\n        round(stats.ttest_ind(gave_2, gave_1, equal_var=False).pvalue, 5),\n        round(stats.ttest_ind(gave_3, gave_2, equal_var=False).pvalue, 5),\n        round(stats.ttest_ind(gave_3, gave_1, equal_var=False).pvalue, 5)\n    ],\n    \"Rate A\": [round(gave_2.mean(), 5), round(gave_3.mean(), 5), round(gave_3.mean(), 5)],\n    \"Rate B\": [round(gave_1.mean(), 5), round(gave_2.mean(), 5), round(gave_1.mean(), 5)],\n    \"Difference (A - B)\": [\n        round(gave_2.mean() - gave_1.mean(), 5),\n        round(gave_3.mean() - gave_2.mean(), 5),\n        round(gave_3.mean() - gave_1.mean(), 5)\n    ]\n})\n\nsummary\n\n/var/folders/h7/9ry6pj514cb7qp5v6btr37ym0000gn/T/ipykernel_20691/2990980929.py:4: FutureWarning:\n\nThe default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n\n\n\n\n\n\n\n\n\n\nComparison\np-value\nRate A\nRate B\nDifference (A - B)\n\n\n\n\n0\n2:1 vs 1:1\n0.33453\n0.02263\n0.02075\n0.00188\n\n\n1\n3:1 vs 2:1\n0.96003\n0.02273\n0.02263\n0.00010\n\n\n2\n3:1 vs 1:1\n0.31011\n0.02273\n0.02075\n0.00198\n\n\n\n\n\n\n\nObserved donation rates:\n1:1 match — 2.07%\n2:1 match — 2.26%\n3:1 match — 2.27%\nThe increase from 1:1 to 2:1 and 3:1 appears small.\nNone of the pairwise comparisons are statistically significant. This supports the paper’s statement on page 8 that larger match ratios do not lead to meaningfully higher donation rates.\n\n\nRegression: Match Ratio Effects\n\n# Regression with dummy variables (baseline: 1:1 match)\nimport statsmodels.formula.api as smf\n\nmatched_data[\"ratio2\"] = (matched_data[\"ratio\"] == 2).astype(int)\nmatched_data[\"ratio3\"] = (matched_data[\"ratio\"] == 3).astype(int)\n\nreg_model = smf.ols(\"gave ~ ratio2 + ratio3\", data=matched_data).fit()\n\n# Clean formatted output\ncoefs = reg_model.params\nstderr = reg_model.bse\npvals = reg_model.pvalues\nconfint = reg_model.conf_int()\n\npd.DataFrame({\n    \"Coefficient\": coefs.round(5),\n    \"Std. Error\": stderr.round(5),\n    \"p-value\": pvals.round(5),\n    \"95% CI Lower\": confint[0].round(5),\n    \"95% CI Upper\": confint[1].round(5)\n}).loc[[\"Intercept\", \"ratio2\", \"ratio3\"]].reset_index().rename(columns={\"index\": \"Term\"})\n\n/var/folders/h7/9ry6pj514cb7qp5v6btr37ym0000gn/T/ipykernel_20691/759364550.py:4: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n/var/folders/h7/9ry6pj514cb7qp5v6btr37ym0000gn/T/ipykernel_20691/759364550.py:5: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\n\n\n\n\n\n\n\nTerm\nCoefficient\nStd. Error\np-value\n95% CI Lower\n95% CI Upper\n\n\n\n\n0\nIntercept\n0.02075\n0.00139\n0.00000\n0.01802\n0.02348\n\n\n1\nratio2\n0.00188\n0.00197\n0.33828\n-0.00197\n0.00574\n\n\n2\nratio3\n0.00198\n0.00197\n0.31332\n-0.00187\n0.00584\n\n\n\n\n\n\n\nRegression results:\nThe baseline (1:1 match) donation rate is about 2.07%.\nThe 2:1 match effect: +0.19 percentage points (not statistically significant).\nThe 3:1 match effect: +0.20 percentage points (also not statistically significant).\nNeither the 2:1 nor 3:1 match ratio coefficients are statistically significant. The results suggest that changing the size of the match ratio does not significantly change donation likelihood relative to 1:1.\n\n\nDifference in Response Rates (Data vs. Regression Coefficients)\n\n# Mean differences and coefficient comparisons\npd.DataFrame([\n    {\n        \"Comparison\": \"2:1 vs 1:1\",\n        \"Raw Mean Difference\": round(gave_2.mean() - gave_1.mean(), 5),\n        \"Regression Coefficient\": round(reg_model.params[\"ratio2\"], 5)\n    },\n    {\n        \"Comparison\": \"3:1 vs 2:1\",\n        \"Raw Mean Difference\": round(gave_3.mean() - gave_2.mean(), 5),\n        \"Regression Coefficient Diff (3 - 2)\": round(reg_model.params[\"ratio3\"] - reg_model.params[\"ratio2\"], 5)\n    },\n    {\n        \"Comparison\": \"3:1 vs 1:1\",\n        \"Raw Mean Difference\": round(gave_3.mean() - gave_1.mean(), 5),\n        \"Regression Coefficient\": round(reg_model.params[\"ratio3\"], 5)\n    }\n])\n\n\n\n\n\n\n\n\nComparison\nRaw Mean Difference\nRegression Coefficient\nRegression Coefficient Diff (3 - 2)\n\n\n\n\n0\n2:1 vs 1:1\n0.00188\n0.00188\nNaN\n\n\n1\n3:1 vs 2:1\n0.00010\nNaN\n0.0001\n\n\n2\n3:1 vs 1:1\n0.00198\n0.00198\nNaN\n\n\n\n\n\n\n\nThe differences in donation rates between 1:1, 2:1, and 3:1 match offers are very small and not statistically significant. These findings replicate the comment on page 8 of Karlan and List (2007): “Larger match ratios relative to a smaller match ratio had no additional impact.”\nThis suggests that donors may respond to the presence of a match, but not necessarily to the size of the match. Psychologically, the idea of having one’s donation matched could serve as a signal of trust or endorsement—but the exact multiplier does not further influence behavior.\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot.\ncharts side by side and scale #### All Respondents: Does Treatment Affect Amount Donated?\n\namount_reg_all = smf.ols(\"amount ~ treatment\", data=data).fit()\n\npd.DataFrame([{\n    \"Treatment Coefficient\": round(amount_reg_all.params[\"treatment\"], 5),\n    \"Std. Error\": round(amount_reg_all.bse[\"treatment\"], 5),\n    \"t-statistic\": round(amount_reg_all.tvalues[\"treatment\"], 3),\n    \"p-value\": round(amount_reg_all.pvalues[\"treatment\"], 5),\n    \"95% CI Lower\": round(amount_reg_all.conf_int().loc[\"treatment\", 0], 5),\n    \"95% CI Upper\": round(amount_reg_all.conf_int().loc[\"treatment\", 1], 5)\n}])\n\n\n\n\n\n\n\n\nTreatment Coefficient\nStd. Error\nt-statistic\np-value\n95% CI Lower\n95% CI Upper\n\n\n\n\n0\n0.15361\n0.08256\n1.861\n0.06282\n-0.00822\n0.31543\n\n\n\n\n\n\n\nCoefficient on treatment ≈ 0.15\np-value ≈ 0.063\nAmong all individuals (including non-donors), the treatment group donated about $0.15 more on average. This effect is marginally significant (p ≈ 0.063). It suggests that matching increases expected donations slightly, but much of that effect may be driven by more people giving (rather than giving more).\nThis suggests that those who received a matching letter donated slightly more on average. However, the result is only marginally significant (at the 10% level). This weak evidence may indicate that the offer of a match has a small impact on the total amount donated—though for most people, the presence of the match does not substantially alter donation size.\n\nConditional on Donation: Do Donors Give More if Matched?\n\n# Subset to donors only\ndonors = data[data[\"gave\"] == 1]\n\n# Linear regression among donors only\namount_reg_donors = smf.ols(\"amount ~ treatment\", data=donors).fit()\n\npd.DataFrame([{\n    \"Treatment Coefficient\": round(amount_reg_donors.params[\"treatment\"], 5),\n    \"Std. Error\": round(amount_reg_donors.bse[\"treatment\"], 5),\n    \"t-statistic\": round(amount_reg_donors.tvalues[\"treatment\"], 3),\n    \"p-value\": round(amount_reg_donors.pvalues[\"treatment\"], 5),\n    \"95% CI Lower\": round(amount_reg_donors.conf_int().loc[\"treatment\", 0], 5),\n    \"95% CI Upper\": round(amount_reg_donors.conf_int().loc[\"treatment\", 1], 5)\n}])\n\n\n\n\n\n\n\n\nTreatment Coefficient\nStd. Error\nt-statistic\np-value\n95% CI Lower\n95% CI Upper\n\n\n\n\n0\n-1.66839\n2.87238\n-0.581\n0.56148\n-7.30477\n3.96799\n\n\n\n\n\n\n\nCoefficient on treatment ≈ -1.67\np-value = 0.561\nAmong those who did donate, receiving a match letter did not significantly change the amount given. In fact, the coefficient is slightly negative, though not significant. Thus, we conclude that while match offers may increase the number of donors, they do not cause donors to give more, conditional on giving.\nThis coefficient does not have a strong causal interpretation, because donation decisions and donation amounts are jointly determined and the sample is selected on gave == 1.\n\n\nDistribution of Donations Among Donors\n\ntreatment_donors = data[(data[\"treatment\"] == 1) & (data[\"gave\"] == 1)]\ncontrol_donors = data[(data[\"treatment\"] == 0) & (data[\"gave\"] == 1)]\n\nmean_treat = treatment_donors[\"amount\"].mean()\nmean_control = control_donors[\"amount\"].mean()\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\n\nsns.histplot(treatment_donors[\"amount\"], bins=30, color=\"orange\", edgecolor=\"black\", ax=axes[0])\naxes[0].axvline(mean_treat, color='red', linestyle='--', label=f\"Mean: ${mean_treat:.2f}\")\naxes[0].set_title(\"Treatment Group\")\naxes[0].set_xlabel(\"Donation Amount\")\naxes[0].set_ylabel(\"Frequency\")\naxes[0].legend()\n\nsns.histplot(control_donors[\"amount\"], bins=30, color=\"orange\", edgecolor=\"black\", ax=axes[1])\naxes[1].axvline(mean_control, color='red', linestyle='--', label=f\"Mean: ${mean_control:.2f}\")\naxes[1].set_title(\"Control Group\")\naxes[1].set_xlabel(\"Donation Amount\")\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n/Users/jnishyu/anaconda3/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning:\n\nuse_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n\n/Users/jnishyu/anaconda3/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning:\n\nuse_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n\n\n\n\n\n\n\n\n\n\nTwo histograms show the distribution of donation amounts for the treatment group and control group, restricted to those who donated. The vertical red line marks the average for each group:\nTreatment Mean: ~$43.87\nControl Mean: ~$45.54\nBoth distributions are right-skewed, with most donors giving small amounts and a few contributing large sums. There is no visible shift in the average due to the treatment.\n\n\nConclusion\nThese analyses support the idea that matching offers increase response rate, but do not change how much people give once they’ve decided to donate. This distinction is important for fundraising strategies: matching may motivate more people to give, but it doesn’t necessarily increase per-donor revenue."
  },
  {
    "objectID": "hw1_questions.html#simulation-experiment",
    "href": "hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters\np_control = 0.018\np_treatment = 0.022\nn_sim = 10000\nnp.random.seed(42)\n# Simulate 10,000 binary outcomes for each group\ncontrol_sim = np.random.binomial(1, p_control, 100000)\ntreatment_sim = np.random.binomial(1, p_treatment, n_sim)\n\n# Vector of differences\ndiffs = treatment_sim - control_sim[:10000]\n\n# Cumulative average of the differences\ncum_avg = np.cumsum(diffs) / np.arange(1, len(diffs) + 1)\n\n# Plot\nplt.figure(figsize=(8, 4))\nplt.plot(cum_avg, label='Cumulative Average Difference', color='orange')\nplt.axhline(y=p_treatment - p_control, color='red', linestyle='--', label='True Difference (0.004)')\nplt.title(\"Law of Large Numbers: Cumulative Average of Simulated Differences\")\nplt.xlabel(\"Simulation Iteration\")\nplt.ylabel(\"Cumulative Average Difference\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nInterpretation\nThis plot demonstrates the Law of Large Numbers. As we simulate more and more observations, the cumulative average of the differences converges toward the true mean difference (0.004). Initially, there’s randomness and fluctuation, but the line stabilizes as the number of observations increases.\nThis convergence is the foundation for using sample averages to estimate population parameters and underpins why large sample sizes give us more reliable estimates in experiments.\n\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters\np_control = 0.018\np_treatment = 0.022\ntrue_diff = p_treatment - p_control\nsample_sizes = [50, 200, 500, 1000]\nn_reps = 1000\n\nnp.random.seed(42)\nhistograms = {}\n\n# Simulate average differences for each sample size\nfor n in sample_sizes:\n    diffs = []\n    for _ in range(n_reps):\n        control_sample = np.random.binomial(1, p_control, n)\n        treatment_sample = np.random.binomial(1, p_treatment, n)\n        diff = treatment_sample.mean() - control_sample.mean()\n        diffs.append(diff)\n    histograms[n] = diffs\n\n# Plot histograms\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\naxes = axes.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    axes[i].hist(histograms[n], bins=30, color='skyblue', edgecolor='black')\n    axes[i].axvline(0, color='red', linestyle='--', label=\"Zero Reference\")\n    axes[i].axvline(true_diff, color='green', linestyle='--', label=\"True Difference (0.004)\")\n    axes[i].set_title(f\"Sample Size = {n}\")\n    axes[i].set_xlabel(\"Mean Difference\")\n    axes[i].set_ylabel(\"Frequency\")\n    axes[i].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nInterpretation\nThese four histograms illustrate how the sampling distribution of the difference in means behaves at increasing sample sizes:\nAt n = 50, the distribution is quite wide and skewed. Zero is within the center-ish but not tightly.\nAs sample size increases, the distribution becomes tighter, more symmetric, and centered.\nBy n = 1000, the distribution of average differences closely resembles a normal distribution centered near the true mean difference (0.004).\nThis is a direct illustration of the Central Limit Theorem:\nAs sample size increases, the distribution of the sample mean difference becomes approximately normal, regardless of the original distribution shape.\nAlso note: zero shifts from being more “middle-ish” in smaller samples to being closer to the tail as the signal (the true effect) dominates the noise."
  },
  {
    "objectID": "hw1_questions (1).html",
    "href": "hw1_questions (1).html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "hw1_questions (1).html#introduction",
    "href": "hw1_questions (1).html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "hw1_questions (1).html#data",
    "href": "hw1_questions (1).html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)."
  },
  {
    "objectID": "hw1_questions (1).html#experimental-results",
    "href": "hw1_questions (1).html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "hw1_questions (1).html#simulation-experiment",
    "href": "hw1_questions (1).html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”"
  },
  {
    "objectID": "blog/project1/hw1_questions.html",
    "href": "blog/project1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to replicate their results. The goal of the experiment was to test whether offering a matching donation—in which a lead donor promises to match contributions from other individuals—would increase the likelihood and/or size of charitable donations. In addition to testing whether matching grants were effective in general, Karlan and List also explored whether the size of the match mattered. Some participants were told that every dollar they donated would be matched 1:1, while others were offered more generous matches (2:1 or 3:1), allowing the researchers to test for differences in donor behavior across match sizes.\nThe experiment is notable for its scale, randomization, and use of real-world donor behavior, which together provide credible evidence of causal effects. Because the fundraising letters were identical in every respect except for the treatment condition, any differences in outcomes across groups can be attributed to the match offer itself. This approach allows for insights not only into how people respond to incentives, but also into broader questions about social influence, perceived impact, and behavioral nudges in charitable giving."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#introduction",
    "href": "blog/project1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThis project seeks to replicate their results. The goal of the experiment was to test whether offering a matching donation—in which a lead donor promises to match contributions from other individuals—would increase the likelihood and/or size of charitable donations. In addition to testing whether matching grants were effective in general, Karlan and List also explored whether the size of the match mattered. Some participants were told that every dollar they donated would be matched 1:1, while others were offered more generous matches (2:1 or 3:1), allowing the researchers to test for differences in donor behavior across match sizes.\nThe experiment is notable for its scale, randomization, and use of real-world donor behavior, which together provide credible evidence of causal effects. Because the fundraising letters were identical in every respect except for the treatment condition, any differences in outcomes across groups can be attributed to the match offer itself. This approach allows for insights not only into how people respond to incentives, but also into broader questions about social influence, perceived impact, and behavioral nudges in charitable giving."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#data",
    "href": "blog/project1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\nimport pandas as pd\n\ndata = pd.read_stata(\"karlan_list_2007.dta\")\ndata.head()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\n\ndata.describe()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio2\nratio3\nsize25\nsize50\nsize100\nsizeno\naskd1\naskd2\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n49978.000000\n49978.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nmean\n0.666813\n0.333187\n0.222311\n0.222211\n0.166723\n0.166623\n0.166723\n0.166743\n0.222311\n0.222291\n...\n0.510245\n0.488715\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\n0.415803\n0.415736\n0.372732\n0.372643\n0.372732\n0.372750\n0.415803\n0.415790\n...\n0.499900\n0.499878\n0.168560\n0.135868\n0.103039\n0.378105\n22027.316665\n0.193405\n0.186599\n0.258633\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n0.000000\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n1.000000\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n8 rows × 48 columns\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another at the 95% confidence level. If randomization was properly executed, we should expect no statistically significant differences in pre-treatment characteristics between the groups.\nI begin by testing the variable mrm2, which captures the number of months since the last donation. This variable is useful for checking balance because it is unrelated to the treatment assignment and reflects donor history.\n\nimport pandas as pd\nimport statsmodels.formula.api as smf\nfrom scipy import stats\n\n\ndata = pd.read_stata(\"karlan_list_2007.dta\")\n\nvars_to_test = [\"mrm2\", \"amount\", \"years\", \"freq\"]\nresults = []\n\nfor var in vars_to_test:\n    subset = data[[\"treatment\", var]].dropna()\n    control = subset[subset[\"treatment\"] == 0][var]\n    treatment = subset[subset[\"treatment\"] == 1][var]\n    \n    # T-test\n    t_stat, p_val = stats.ttest_ind(treatment, control, equal_var=False)\n    \n    # Linear regression\n    regression = smf.ols(f\"{var} ~ treatment\", data=subset).fit()\n    coef = regression.params[\"treatment\"]\n    reg_p = regression.pvalues[\"treatment\"]\n    \n    # Difference in means\n    diff = treatment.mean() - control.mean()\n    \n    results.append({\n        \"Variable\": var,\n        \"Diff (Treat - Control)\": round(diff, 5),\n        \"T-test p-value\": round(p_val, 5),\n        \"Regression Coef\": round(coef, 5),\n        \"Regression p-value\": round(reg_p, 5)\n    })\n\npd.DataFrame(results)\n\n\n\n\n\n\n\n\nVariable\nDiff (Treat - Control)\nT-test p-value\nRegression Coef\nRegression p-value\n\n\n\n\n0\nmrm2\n0.01369\n0.90485\n0.01369\n0.90489\n\n\n1\namount\n0.15361\n0.05509\n0.15361\n0.06282\n\n\n2\nyears\n-0.05755\n0.27532\n-0.05755\n0.27002\n\n\n3\nfreq\n-0.01198\n0.91174\n-0.01198\n0.91170\n\n\n\n\n\n\n\nThe table of results above shows no statistically significant differences at the 5% level for any variable (p-values &gt; 0.05), though amount is marginally close (p ≈ 0.06 in the regression). This is consistent with proper random assignment.\nThese checks are similar to what Karlan and List report in Table 1 of the original paper, which reassures readers that the treatment effect estimates later in the paper can be interpreted as causal. If pre-treatment covariates are balanced, then observed differences in outcomes are more likely attributable to the randomized treatment itself.\nThese results mirror those presented in Table 1 of Karlan and List (2007), which shows no significant differences between the groups in prior donation behavior and demographic characteristics. Table 1 serves to reassure the reader that any observed treatment effects later in the analysis can be confidently attributed to the randomized intervention rather than pre-existing differences between groups."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#experimental-results",
    "href": "blog/project1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nDonation Rate by Group\n\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Calculate donation rates\ndonation_rates = data.groupby(\"treatment\")[\"gave\"].mean().reset_index()\ndonation_rates[\"group\"] = donation_rates[\"treatment\"].map({0: \"Control\", 1: \"Treatment\"})\n\n# Create barplot\nplt.figure(figsize=(6, 4))\nax = sns.barplot(data=donation_rates, x=\"group\", y=\"gave\")\nplt.ylabel(\"Proportion Donated\")\nplt.xlabel(\"\")\nplt.title(\"Donation Rate by Group\")\nplt.ylim(0, 0.03)\nplt.grid(axis='y')\n\n# Add percentage labels on top\nfor i, val in enumerate(donation_rates[\"gave\"]):\n    ax.text(i, val + 0.0005, f\"{val:.3%}\", ha='center', va='bottom')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis bar plot shows that the treatment group—who received matching grant letters—had a higher donation rate than the control group.\n\n\nT-Test and Linear Regression\n\ntreat_gave = data[data['treatment'] == 1]['gave']\ncontrol_gave = data[data['treatment'] == 0]['gave']\nt_stat, t_pval = stats.ttest_ind(treat_gave, control_gave, equal_var=False)\n\n# Format output\npd.DataFrame([{\n    \"T-test Statistic\": round(t_stat, 3),\n    \"T-test p-value\": round(t_pval, 5)\n}])\n\n\n\n\n\n\n\n\nT-test Statistic\nT-test p-value\n\n\n\n\n0\n3.209\n0.00133\n\n\n\n\n\n\n\n\ngave_regression = smf.ols(\"gave ~ treatment\", data=data).fit()\ncoef = gave_regression.params[\"treatment\"]\nstd_err = gave_regression.bse[\"treatment\"]\np_val = gave_regression.pvalues[\"treatment\"]\nconf_int = gave_regression.conf_int().loc[\"treatment\"]\n\n# Format output\npd.DataFrame([{\n    \"Treatment Coefficient\": round(coef, 5),\n    \"Standard Error\": round(std_err, 5),\n    \"p-value\": round(p_val, 5),\n    \"95% CI Lower\": round(conf_int[0], 5),\n    \"95% CI Upper\": round(conf_int[1], 5)\n}])\n\n\n\n\n\n\n\n\nTreatment Coefficient\nStandard Error\np-value\n95% CI Lower\n95% CI Upper\n\n\n\n\n0\n0.00418\n0.00135\n0.00193\n0.00154\n0.00682\n\n\n\n\n\n\n\nThe difference in donation rates is statistically significant at the 1% level.\nThe treatment group is more likely to donate, increasing the probability of giving by about 0.42 percentage points.\nThis replicates the result from Table 2A Panel A in Karlan & List (2007), showing that a match offer significantly boosts participation.\nOLS regression shows a statistically significant positive coefficient (≈ 0.0042) on the treatment variable. This confirms the t-test: assignment to the treatment group increased the likelihood of making a donation.\nThis suggests that even a small behavioral nudge like mentioning a matching donation makes people more likely to contribute to charity. People respond to the perception of increased impact.\n\n# Probit model\nimport statsmodels.api as sm\n\nprobit_model = smf.probit(\"gave ~ treatment\", data=data).fit()\ncoef = probit_model.params[\"treatment\"]\nstd_err = probit_model.bse[\"treatment\"]\np_val = probit_model.pvalues[\"treatment\"]\nconf_int = probit_model.conf_int().loc[\"treatment\"]\n\n# Output summary\npd.DataFrame([{\n    \"Probit Coefficient\": round(coef, 5),\n    \"Standard Error\": round(std_err, 5),\n    \"p-value\": round(p_val, 5),\n    \"95% CI Lower\": round(conf_int[0], 5),\n    \"95% CI Upper\": round(conf_int[1], 5)\n}])\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\n\n\n\n\n\n\n\n\nProbit Coefficient\nStandard Error\np-value\n95% CI Lower\n95% CI Upper\n\n\n\n\n0\n0.08678\n0.02788\n0.00185\n0.03214\n0.14143\n\n\n\n\n\n\n\nThe probit model replicates Table 3, Column 1 of Karlan and List (2007), with a significant positive treatment effect (coefficient ≈ 0.087, p ≈ 0.002). This again confirms that individuals are more likely to donate when offered a matching grant.\nTogether, these results demonstrate a consistent and statistically significant treatment effect, providing strong evidence that the framing of charitable solicitations matters for donor behavior.\nThe match incentive not only has a practical impact but also a statistically robust one, even under a probit framework.\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\nResponse Rates by Match Ratio\n\nmatched_data = data[(data[\"treatment\"] == 1) & (data[\"ratio\"].isin([1, 2, 3]))]\n\n# Calculate means\nresponse_rates = matched_data.groupby(\"ratio\")[\"gave\"].mean()\n\n# Separate groups for pairwise comparisons\ngave_1 = matched_data[matched_data[\"ratio\"] == 1][\"gave\"]\ngave_2 = matched_data[matched_data[\"ratio\"] == 2][\"gave\"]\ngave_3 = matched_data[matched_data[\"ratio\"] == 3][\"gave\"]\n\n# T-tests for pairwise comparisons\nfrom scipy import stats\n\nsummary = pd.DataFrame({\n    \"Comparison\": [\"2:1 vs 1:1\", \"3:1 vs 2:1\", \"3:1 vs 1:1\"],\n    \"p-value\": [\n        round(stats.ttest_ind(gave_2, gave_1, equal_var=False).pvalue, 5),\n        round(stats.ttest_ind(gave_3, gave_2, equal_var=False).pvalue, 5),\n        round(stats.ttest_ind(gave_3, gave_1, equal_var=False).pvalue, 5)\n    ],\n    \"Rate A\": [round(gave_2.mean(), 5), round(gave_3.mean(), 5), round(gave_3.mean(), 5)],\n    \"Rate B\": [round(gave_1.mean(), 5), round(gave_2.mean(), 5), round(gave_1.mean(), 5)],\n    \"Difference (A - B)\": [\n        round(gave_2.mean() - gave_1.mean(), 5),\n        round(gave_3.mean() - gave_2.mean(), 5),\n        round(gave_3.mean() - gave_1.mean(), 5)\n    ]\n})\n\nsummary\n\n/var/folders/h7/9ry6pj514cb7qp5v6btr37ym0000gn/T/ipykernel_40228/2990980929.py:4: FutureWarning:\n\nThe default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n\n\n\n\n\n\n\n\n\n\nComparison\np-value\nRate A\nRate B\nDifference (A - B)\n\n\n\n\n0\n2:1 vs 1:1\n0.33453\n0.02263\n0.02075\n0.00188\n\n\n1\n3:1 vs 2:1\n0.96003\n0.02273\n0.02263\n0.00010\n\n\n2\n3:1 vs 1:1\n0.31011\n0.02273\n0.02075\n0.00198\n\n\n\n\n\n\n\nObserved donation rates:\n1:1 match — 2.07%\n2:1 match — 2.26%\n3:1 match — 2.27%\nThe increase from 1:1 to 2:1 and 3:1 appears small.\nNone of the pairwise comparisons are statistically significant. This supports the paper’s statement on page 8 that larger match ratios do not lead to meaningfully higher donation rates.\n\n\nRegression: Match Ratio Effects\n\n# Regression with dummy variables (baseline: 1:1 match)\nimport statsmodels.formula.api as smf\n\nmatched_data[\"ratio2\"] = (matched_data[\"ratio\"] == 2).astype(int)\nmatched_data[\"ratio3\"] = (matched_data[\"ratio\"] == 3).astype(int)\n\nreg_model = smf.ols(\"gave ~ ratio2 + ratio3\", data=matched_data).fit()\n\n# Clean formatted output\ncoefs = reg_model.params\nstderr = reg_model.bse\npvals = reg_model.pvalues\nconfint = reg_model.conf_int()\n\npd.DataFrame({\n    \"Coefficient\": coefs.round(5),\n    \"Std. Error\": stderr.round(5),\n    \"p-value\": pvals.round(5),\n    \"95% CI Lower\": confint[0].round(5),\n    \"95% CI Upper\": confint[1].round(5)\n}).loc[[\"Intercept\", \"ratio2\", \"ratio3\"]].reset_index().rename(columns={\"index\": \"Term\"})\n\n/var/folders/h7/9ry6pj514cb7qp5v6btr37ym0000gn/T/ipykernel_40228/759364550.py:4: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n/var/folders/h7/9ry6pj514cb7qp5v6btr37ym0000gn/T/ipykernel_40228/759364550.py:5: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\n\n\n\n\n\n\n\nTerm\nCoefficient\nStd. Error\np-value\n95% CI Lower\n95% CI Upper\n\n\n\n\n0\nIntercept\n0.02075\n0.00139\n0.00000\n0.01802\n0.02348\n\n\n1\nratio2\n0.00188\n0.00197\n0.33828\n-0.00197\n0.00574\n\n\n2\nratio3\n0.00198\n0.00197\n0.31332\n-0.00187\n0.00584\n\n\n\n\n\n\n\nRegression results:\nThe baseline (1:1 match) donation rate is about 2.07%.\nThe 2:1 match effect: +0.19 percentage points (not statistically significant).\nThe 3:1 match effect: +0.20 percentage points (also not statistically significant).\nNeither the 2:1 nor 3:1 match ratio coefficients are statistically significant. The results suggest that changing the size of the match ratio does not significantly change donation likelihood relative to 1:1.\n\n\nDifference in Response Rates (Data vs. Regression Coefficients)\n\n# Mean differences and coefficient comparisons\npd.DataFrame([\n    {\n        \"Comparison\": \"2:1 vs 1:1\",\n        \"Raw Mean Difference\": round(gave_2.mean() - gave_1.mean(), 5),\n        \"Regression Coefficient\": round(reg_model.params[\"ratio2\"], 5)\n    },\n    {\n        \"Comparison\": \"3:1 vs 2:1\",\n        \"Raw Mean Difference\": round(gave_3.mean() - gave_2.mean(), 5),\n        \"Regression Coefficient Diff (3 - 2)\": round(reg_model.params[\"ratio3\"] - reg_model.params[\"ratio2\"], 5)\n    },\n    {\n        \"Comparison\": \"3:1 vs 1:1\",\n        \"Raw Mean Difference\": round(gave_3.mean() - gave_1.mean(), 5),\n        \"Regression Coefficient\": round(reg_model.params[\"ratio3\"], 5)\n    }\n])\n\n\n\n\n\n\n\n\nComparison\nRaw Mean Difference\nRegression Coefficient\nRegression Coefficient Diff (3 - 2)\n\n\n\n\n0\n2:1 vs 1:1\n0.00188\n0.00188\nNaN\n\n\n1\n3:1 vs 2:1\n0.00010\nNaN\n0.0001\n\n\n2\n3:1 vs 1:1\n0.00198\n0.00198\nNaN\n\n\n\n\n\n\n\nThe differences in donation rates between 1:1, 2:1, and 3:1 match offers are very small and not statistically significant. These findings replicate the comment on page 8 of Karlan and List (2007): “Larger match ratios relative to a smaller match ratio had no additional impact.”\nThis suggests that donors may respond to the presence of a match, but not necessarily to the size of the match. Psychologically, the idea of having one’s donation matched could serve as a signal of trust or endorsement—but the exact multiplier does not further influence behavior.\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ncharts side by side and scale #### All Respondents: Does Treatment Affect Amount Donated?\n\namount_reg_all = smf.ols(\"amount ~ treatment\", data=data).fit()\n\npd.DataFrame([{\n    \"Treatment Coefficient\": round(amount_reg_all.params[\"treatment\"], 5),\n    \"Std. Error\": round(amount_reg_all.bse[\"treatment\"], 5),\n    \"t-statistic\": round(amount_reg_all.tvalues[\"treatment\"], 3),\n    \"p-value\": round(amount_reg_all.pvalues[\"treatment\"], 5),\n    \"95% CI Lower\": round(amount_reg_all.conf_int().loc[\"treatment\", 0], 5),\n    \"95% CI Upper\": round(amount_reg_all.conf_int().loc[\"treatment\", 1], 5)\n}])\n\n\n\n\n\n\n\n\nTreatment Coefficient\nStd. Error\nt-statistic\np-value\n95% CI Lower\n95% CI Upper\n\n\n\n\n0\n0.15361\n0.08256\n1.861\n0.06282\n-0.00822\n0.31543\n\n\n\n\n\n\n\nCoefficient on treatment ≈ 0.15\np-value ≈ 0.063\nAmong all individuals (including non-donors), the treatment group donated about $0.15 more on average. This effect is marginally significant (p ≈ 0.063). It suggests that matching increases expected donations slightly, but much of that effect may be driven by more people giving (rather than giving more).\nThis suggests that those who received a matching letter donated slightly more on average. However, the result is only marginally significant (at the 10% level). This weak evidence may indicate that the offer of a match has a small impact on the total amount donated—though for most people, the presence of the match does not substantially alter donation size.\n\nConditional on Donation: Do Donors Give More if Matched?\n\n# Subset to donors only\ndonors = data[data[\"gave\"] == 1]\n\n# Linear regression among donors only\namount_reg_donors = smf.ols(\"amount ~ treatment\", data=donors).fit()\n\npd.DataFrame([{\n    \"Treatment Coefficient\": round(amount_reg_donors.params[\"treatment\"], 5),\n    \"Std. Error\": round(amount_reg_donors.bse[\"treatment\"], 5),\n    \"t-statistic\": round(amount_reg_donors.tvalues[\"treatment\"], 3),\n    \"p-value\": round(amount_reg_donors.pvalues[\"treatment\"], 5),\n    \"95% CI Lower\": round(amount_reg_donors.conf_int().loc[\"treatment\", 0], 5),\n    \"95% CI Upper\": round(amount_reg_donors.conf_int().loc[\"treatment\", 1], 5)\n}])\n\n\n\n\n\n\n\n\nTreatment Coefficient\nStd. Error\nt-statistic\np-value\n95% CI Lower\n95% CI Upper\n\n\n\n\n0\n-1.66839\n2.87238\n-0.581\n0.56148\n-7.30477\n3.96799\n\n\n\n\n\n\n\nCoefficient on treatment ≈ -1.67\np-value = 0.561\nAmong those who did donate, receiving a match letter did not significantly change the amount given. In fact, the coefficient is slightly negative, though not significant. Thus, we conclude that while match offers may increase the number of donors, they do not cause donors to give more, conditional on giving.\nThis coefficient does not have a strong causal interpretation, because donation decisions and donation amounts are jointly determined and the sample is selected on gave == 1.\n\n\nDistribution of Donations Among Donors\n\ntreatment_donors = data[(data[\"treatment\"] == 1) & (data[\"gave\"] == 1)]\ncontrol_donors = data[(data[\"treatment\"] == 0) & (data[\"gave\"] == 1)]\n\nmean_treat = treatment_donors[\"amount\"].mean()\nmean_control = control_donors[\"amount\"].mean()\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\n\nsns.histplot(treatment_donors[\"amount\"], bins=30, color=\"orange\", edgecolor=\"black\", ax=axes[0])\naxes[0].axvline(mean_treat, color='red', linestyle='--', label=f\"Mean: ${mean_treat:.2f}\")\naxes[0].set_title(\"Treatment Group\")\naxes[0].set_xlabel(\"Donation Amount\")\naxes[0].set_ylabel(\"Frequency\")\naxes[0].legend()\n\nsns.histplot(control_donors[\"amount\"], bins=30, color=\"orange\", edgecolor=\"black\", ax=axes[1])\naxes[1].axvline(mean_control, color='red', linestyle='--', label=f\"Mean: ${mean_control:.2f}\")\naxes[1].set_title(\"Control Group\")\naxes[1].set_xlabel(\"Donation Amount\")\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n/Users/jnishyu/anaconda3/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning:\n\nuse_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n\n/Users/jnishyu/anaconda3/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning:\n\nuse_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n\n\n\n\n\n\n\n\n\n\nTwo histograms show the distribution of donation amounts for the treatment group and control group, restricted to those who donated. The vertical red line marks the average for each group:\nTreatment Mean: ~$43.87\nControl Mean: ~$45.54\nBoth distributions are right-skewed, with most donors giving small amounts and a few contributing large sums. There is no visible shift in the average due to the treatment.\n\n\nConclusion\nThese analyses support the idea that matching offers increase response rate, but do not change how much people give once they’ve decided to donate. This distinction is important for fundraising strategies: matching may motivate more people to give, but it doesn’t necessarily increase per-donor revenue."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#simulation-experiment",
    "href": "blog/project1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters\np_control = 0.018\np_treatment = 0.022\nn_sim = 10000\nnp.random.seed(42)\n# Simulate 10,000 binary outcomes for each group\ncontrol_sim = np.random.binomial(1, p_control, 100000)\ntreatment_sim = np.random.binomial(1, p_treatment, n_sim)\n\n# Vector of differences\ndiffs = treatment_sim - control_sim[:10000]\n\n# Cumulative average of the differences\ncum_avg = np.cumsum(diffs) / np.arange(1, len(diffs) + 1)\n\n# Plot\nplt.figure(figsize=(8, 4))\nplt.plot(cum_avg, label='Cumulative Average Difference', color='orange')\nplt.axhline(y=p_treatment - p_control, color='red', linestyle='--', label='True Difference (0.004)')\nplt.title(\"Law of Large Numbers: Cumulative Average of Simulated Differences\")\nplt.xlabel(\"Simulation Iteration\")\nplt.ylabel(\"Cumulative Average Difference\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis plot demonstrates the Law of Large Numbers. As we simulate more and more observations, the cumulative average of the differences converges toward the true mean difference (0.004). Initially, there’s randomness and fluctuation, but the line stabilizes as the number of observations increases.\nThis convergence is the foundation for using sample averages to estimate population parameters and underpins why large sample sizes give us more reliable estimates in experiments.\n\n\nCentral Limit Theorem\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters\np_control = 0.018\np_treatment = 0.022\ntrue_diff = p_treatment - p_control\nsample_sizes = [50, 200, 500, 1000]\nn_reps = 1000\n\nnp.random.seed(42)\nhistograms = {}\n\n# Simulate average differences for each sample size\nfor n in sample_sizes:\n    diffs = []\n    for _ in range(n_reps):\n        control_sample = np.random.binomial(1, p_control, n)\n        treatment_sample = np.random.binomial(1, p_treatment, n)\n        diff = treatment_sample.mean() - control_sample.mean()\n        diffs.append(diff)\n    histograms[n] = diffs\n\n# Plot histograms\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\naxes = axes.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    axes[i].hist(histograms[n], bins=30, color='skyblue', edgecolor='black')\n    axes[i].axvline(0, color='red', linestyle='--', label=\"Zero Reference\")\n    axes[i].axvline(true_diff, color='green', linestyle='--', label=\"True Difference (0.004)\")\n    axes[i].set_title(f\"Sample Size = {n}\")\n    axes[i].set_xlabel(\"Mean Difference\")\n    axes[i].set_ylabel(\"Frequency\")\n    axes[i].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThese four histograms illustrate how the sampling distribution of the difference in means behaves at increasing sample sizes:\nAt n = 50, the distribution is quite wide and skewed. Zero is within the center-ish but not tightly.\nAs sample size increases, the distribution becomes tighter, more symmetric, and centered.\nBy n = 1000, the distribution of average differences closely resembles a normal distribution centered near the true mean difference (0.004).\nThis is a direct illustration of the Central Limit Theorem:\nAs sample size increases, the distribution of the sample mean difference becomes approximately normal, regardless of the original distribution shape.\nAlso note: zero shifts from being more “middle-ish” in smaller samples to being closer to the tail as the signal (the true effect) dominates the noise."
  }
]